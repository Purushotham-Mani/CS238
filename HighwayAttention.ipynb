{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Jwwj-WlojWpU9zFfvcs807unQFP8IINU",
      "authorship_tag": "ABX9TyPPANnkb/R5b3qVC7n4lDsy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Purushotham-Mani/CS238/blob/main/HighwayAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M07-Q_o6PbdG",
        "outputId": "b35e8f4e-dcf0-42dc-96df-3211ff4cffa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting highway-env\n",
            "  Downloading highway_env-1.10.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gymnasium>=1.0.0a2 (from highway-env)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting farama-notifications>=0.0.1 (from highway-env)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from highway-env) (1.26.4)\n",
            "Requirement already satisfied: pygame>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from highway-env) (2.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from highway-env) (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from highway-env) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from highway-env) (1.13.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a2->highway-env) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a2->highway-env) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->highway-env) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->highway-env) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->highway-env) (1.16.0)\n",
            "Downloading highway_env-1.10.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: farama-notifications, gymnasium, highway-env\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 highway-env-1.10.1\n",
            "Collecting tensorboardx\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (4.25.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay, tensorboardx\n",
            "Successfully installed pyvirtualdisplay-3.0 tensorboardx-2.6.2.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 7,815 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
            "Fetched 7,815 kB in 0s (18.1 MB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install highway-env\n",
        "!pip install tensorboardx gym pyvirtualdisplay\n",
        "!apt-get install -y xvfb ffmpeg\n",
        "# Environment\n",
        "import gymnasium as gym\n",
        "import highway_env\n",
        "\n",
        "gym.register_envs(highway_env)\n",
        "\n",
        "# Models and computation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from collections import namedtuple, deque\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm.notebook import trange\n",
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_videos(path=\"videos\"):\n",
        "    html = []\n",
        "    for mp4 in Path(path).glob(\"*.mp4\"):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                      loop controls style=\"height: 400px;\">\n",
        "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                 </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "metadata": {
        "id": "y4Ii-N0ZPrgX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, embed_dim):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim, embed_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "9sHZ2VU0PwCn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EgoAttention(nn.Module):\n",
        "  def __init__(self, embed_dim, num_heads):\n",
        "    super(EgoAttention, self).__init__()\n",
        "    self.Q = nn.Linear(embed_dim, embed_dim)\n",
        "    self.K = nn.Linear(embed_dim, embed_dim)\n",
        "    self.V = nn.Linear(embed_dim, embed_dim)\n",
        "    self.fe = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    self.embed_dim = embed_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = embed_dim // num_heads\n",
        "\n",
        "  def forward(self, ego_embed, vehicle_embeds):\n",
        "\n",
        "    batch_size = ego_embed.size(0)\n",
        "\n",
        "    # Linear transformations for query, key, value\n",
        "    Q = self.Q(ego_embed).view(batch_size, 1, self.num_heads, self.head_dim)\n",
        "    K = self.K(vehicle_embeds).view(batch_size, -1, self.num_heads, self.head_dim)\n",
        "    V = self.V(vehicle_embeds).view(batch_size, -1, self.num_heads, self.head_dim)\n",
        "\n",
        "    # Reshape to (batch_size, num_heads, seq_len, head_dim)\n",
        "    Q = Q.permute(0, 2, 1, 3)  # (batch_size, num_heads, 1, head_dim)\n",
        "    K = K.permute(0, 2, 1, 3)  # (batch_size, num_heads, num_vehicles, head_dim)\n",
        "    V = V.permute(0, 2, 1, 3)  # (batch_size, num_heads, num_vehicles, head_dim)\n",
        "\n",
        "    # Scaled Dot-Product Attention\n",
        "    attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "    attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "    attention_output = torch.matmul(attention_weights, V)  # (batch_size, num_heads, 1, head_dim)\n",
        "\n",
        "    # Concatenate heads and project\n",
        "    attention_output = attention_output.permute(0, 2, 1, 3).contiguous()\n",
        "    attention_output = attention_output.view(batch_size, -1, self.embed_dim)  # (batch_size, 1, embed_dim)\n",
        "    output = self.fe(attention_output.squeeze(1))\n",
        "\n",
        "    return output, attention_weights\n",
        "    # Q = self.Q(ego_embed).unsqueeze(1)\n",
        "    # K = self.K(vehicle_embeds)\n",
        "    # V = self.V(vehicle_embeds)\n",
        "\n",
        "    # scores = torch.matmul(Q, K.transpose(-2, -1))/np.sqrt(K.size(-1))\n",
        "    # attention_weights = F.softmax(scores, dim=-1)\n",
        "    # output = torch.matmul(attention_weights, V)\n",
        "\n",
        "    # return output.squeeze(1), attention_weights"
      ],
      "metadata": {
        "id": "EP0myqOxVz8O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDQN(nn.Module):\n",
        "  def __init__(self, input_dim, embed_dim, num_heads, output_dim, lr):\n",
        "    super(AttentionDQN, self).__init__()\n",
        "    self.encoder = Encoder(input_dim, embed_dim)\n",
        "    self.ego_attention = EgoAttention(embed_dim, num_heads)\n",
        "    self.f = nn.Linear(embed_dim, output_dim)\n",
        "\n",
        "    self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "    self.loss = nn.MSELoss()\n",
        "    self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    print(self.device)\n",
        "    self.to(self.device)\n",
        "\n",
        "  def forward(self, ego_state, vehicle_states):\n",
        "    ego_embed = self.encoder(ego_state)\n",
        "    vehicle_embeds = self.encoder(vehicle_states)\n",
        "    ego_attention, attention_weights = self.ego_attention(ego_embed, vehicle_embeds)\n",
        "    q_values = self.f(ego_attention)\n",
        "    return q_values, attention_weights"
      ],
      "metadata": {
        "id": "Z5qgYqqUjLDK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "  def __init__(self, input_dim, embed_dim, output_dim, num_heads = 2, lr = 1e-4, gamma = 0.95, epsilon = 1, max_mem_size=100000, eps_end=0.01, eps_dec=5e-4):\n",
        "    self.gamma = gamma\n",
        "    self.epsilon = epsilon\n",
        "    self.eps = 1\n",
        "    self.eps_min = eps_end\n",
        "    self.eps_dec = eps_dec\n",
        "    self.mem_size = max_mem_size\n",
        "    self.batch_size = 64\n",
        "    self.action_space = [i for i in range(output_dim)]\n",
        "\n",
        "    self.Q_fn = AttentionDQN(input_dim[1], embed_dim, num_heads, output_dim, lr)\n",
        "\n",
        "    self.mem_cntr = 0\n",
        "    self.state_memory = np.zeros((self.mem_size, *input_dim), dtype=np.float32) #have to adapt this\n",
        "    self.new_state_memory = np.zeros((self.mem_size, *input_dim), dtype=np.float32)\n",
        "    self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
        "    self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
        "    self.terminal_memory = np.zeros(self.mem_size, dtype=bool)\n",
        "\n",
        "  def store_transition(self, state, action, reward, state_, done):\n",
        "    index = self.mem_cntr % self.mem_size\n",
        "\n",
        "    self.state_memory[index] = state\n",
        "    self.new_state_memory[index] = state_\n",
        "    self.reward_memory[index] = reward\n",
        "    self.action_memory[index] = action\n",
        "    self.terminal_memory[index] = done\n",
        "\n",
        "    self.mem_cntr += 1\n",
        "\n",
        "  def choose_action(self, ego_features, vehicle_features):\n",
        "    if np.random.random() > self.epsilon:\n",
        "      ego = torch.tensor(ego_features).to(self.Q_fn.device).unsqueeze(0)\n",
        "      vehicles = torch.tensor(vehicle_features).to(self.Q_fn.device).unsqueeze(0)\n",
        "      q_values, _ = self.Q_fn(ego, vehicles)\n",
        "      action = torch.argmax(q_values).item()\n",
        "    else:\n",
        "      action = np.random.choice(self.action_space)\n",
        "    return action\n",
        "\n",
        "  def train(self):\n",
        "    if self.mem_cntr < self.batch_size:\n",
        "      return\n",
        "\n",
        "    self.Q_fn.optimizer.zero_grad()\n",
        "    max_mem = min(self.mem_cntr, self.mem_size)\n",
        "    batch = np.random.choice(max_mem, self.batch_size, replace=False)\n",
        "\n",
        "    batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
        "\n",
        "    state_batch = torch.tensor(self.state_memory[batch]).to(self.Q_fn.device)\n",
        "    new_state_batch = torch.tensor(self.new_state_memory[batch]).to(self.Q_fn.device)\n",
        "    reward_batch = torch.tensor(self.reward_memory[batch]).to(self.Q_fn.device)\n",
        "    terminal_batch = torch.tensor(self.terminal_memory[batch]).to(self.Q_fn.device)\n",
        "    action_batch = self.action_memory[batch]\n",
        "\n",
        "    q_eval, _ = self.Q_fn.forward(state_batch[:,0,:],state_batch) ##adapt\n",
        "    q_eval = q_eval[batch_index, action_batch]\n",
        "    q_next, _ = self.Q_fn.forward(new_state_batch[:,0,:],new_state_batch)\n",
        "    q_next[terminal_batch] = 0.0\n",
        "\n",
        "    q_target = reward_batch + self.gamma * torch.max(q_next, dim=1)[0]\n",
        "\n",
        "    loss = self.Q_fn.loss(q_target, q_eval).to(self.Q_fn.device)\n",
        "    loss.backward()\n",
        "    self.Q_fn.optimizer.step()\n",
        "\n",
        "    self.epsilon = self.epsilon - self.eps_dec if self.epsilon > self.eps_min else self.eps_min"
      ],
      "metadata": {
        "id": "Pq75xeVFkxGp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Highway Environment"
      ],
      "metadata": {
        "id": "7p8ZeaP-bb75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "igJ9sgEUnG7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"highway-v0\")\n",
        "# Default Config: Observation: Kinematics, Actions: DiscreteMetaAction\n",
        "# ACTIONS_ALL = {0: 'LANE_LEFT',1: 'IDLE',2: 'LANE_RIGHT',3: 'FASTER',4: 'SLOWER'}\n",
        "\n",
        "agent = Agent(input_dim=env.observation_space.shape, embed_dim = 128, output_dim=env.action_space.n)\n",
        "scores, eps_history = [], []\n",
        "n_games = 50\n",
        "if Path(\"./highway_weights\").exists():\n",
        "  agent.Q_fn.load_state_dict(torch.load(\"./highway_weights\", weights_only=True))\n",
        "for i in range(n_games):\n",
        "  done = False\n",
        "  score = 0\n",
        "  observation, info = env.reset()\n",
        "  while not done:\n",
        "    action = agent.choose_action(observation[0,:],observation)\n",
        "    observation_, reward, done, truncated, info = env.step(action)\n",
        "    score += reward\n",
        "    agent.store_transition(observation, action, reward, observation_, done)\n",
        "    agent.train()\n",
        "    # torch.save(agent.Q_fn.state_dict(),\"./highway_weights\" )\n",
        "    observation = observation_\n",
        "  scores.append(score)\n",
        "  eps_history.append(agent.epsilon)\n",
        "\n",
        "  avg_score = np.mean(scores[-100:])\n",
        "  print('episode ', i, 'score %.2f' % score, 'average score %.2f' % avg_score,'epsilon %.2f' % agent.epsilon)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "YMOiig8GQvkr",
        "outputId": "c117d9e8-f745-4427-bf3b-fc88096cf06b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "episode  0 score 12.03 average score 12.03 epsilon 1.00\n",
            "episode  1 score 5.49 average score 8.76 epsilon 1.00\n",
            "episode  2 score 1.67 average score 6.40 epsilon 1.00\n",
            "episode  3 score 5.67 average score 6.21 epsilon 1.00\n",
            "episode  4 score 30.27 average score 11.02 epsilon 1.00\n",
            "episode  5 score 14.26 average score 11.56 epsilon 0.99\n",
            "episode  6 score 6.02 average score 10.77 epsilon 0.98\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d0ac319b77a9>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mobservation_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    320\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    321\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/highway_env/envs/common/abstract.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_frequency\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/highway_env/envs/common/abstract.py\u001b[0m in \u001b[0;36m_simulate\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"simulation_frequency\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/highway_env/road/road.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, dt)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvehicle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvehicles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvehicles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                 \u001b[0mvehicle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_collisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0mvehicle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_collisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/highway_env/vehicle/objects.py\u001b[0m in \u001b[0;36mhandle_collisions\u001b[0;34m(self, other, dt)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollidable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollidable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mintersecting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwill_intersect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_colliding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwill_intersect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolid\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/highway_env/vehicle/objects.py\u001b[0m in \u001b[0;36m_is_colliding\u001b[0;34m(self, other, dt)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Accurate rectangular check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         return utils.are_polygons_intersecting(\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvelocity\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvelocity\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         )\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/highway_env/vehicle/objects.py\u001b[0m in \u001b[0;36mpolygon\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         points = np.array(\n\u001b[0m\u001b[1;32m    170\u001b[0m             [\n\u001b[1;32m    171\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLENGTH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWIDTH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize"
      ],
      "metadata": {
        "id": "ZVm5RENqnJj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wont run, have to edit\n",
        "\n",
        "env = gym.make(\"highway-v0\",render_mode=\"rgb_array\")\n",
        "# Default Config: Observation: Kinematics, Actions: DiscreteMetaAction\n",
        "# ACTIONS_ALL = {0: 'LANE_LEFT',1: 'IDLE',2: 'LANE_RIGHT',3: 'FASTER',4: 'SLOWER'}\n",
        "# Obeservations : Vehicle x y vx vy / first row is always ego vehicle\n",
        "env = RecordVideo(env, video_folder=\"./videos\", episode_trigger=lambda e: True)\n",
        "observation, info = env.reset()\n",
        "done = False\n",
        "score = 0\n",
        "while not done:\n",
        "    state = torch.tensor(np.array(observation.reshape((1,-1)))).to(agent.Q_fn.device) ## may need to edit this\n",
        "    actions = agent.Q_fn.forward(state)\n",
        "    action = torch.argmax(actions).item()\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "    score += reward\n",
        "    observation = obs\n",
        "print('score %.2f' % score)\n",
        "env.close()\n",
        "show_videos()"
      ],
      "metadata": {
        "id": "9wqFl_qem-8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Intersection Environment"
      ],
      "metadata": {
        "id": "YLocki7DboIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train turning left"
      ],
      "metadata": {
        "id": "PrgHw1PGnNCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"intersection-v0\")\n",
        "env.unwrapped.config[\"destination\"] = \"o3\"   ## to decide where to turn\n",
        "\n",
        "# Default Config: Observation: Kinematics, Actions: DiscreteMetaAction\n",
        "# ACTIONS_ALL = {0: 'LANE_LEFT',1: 'IDLE',2: 'LANE_RIGHT',3: 'FASTER',4: 'SLOWER'}\n",
        "\n",
        "agent = Agent(input_dim=env.observation_space.shape, embed_dim = 128, output_dim=env.action_space.n)\n",
        "scores, eps_history = [], []\n",
        "n_games = 500\n",
        "if Path(\"./intersection_weights\").exists():\n",
        "  agent.Q_fn.load_state_dict(torch.load(\"./intersection_weights\", weights_only=True))\n",
        "for i in range(n_games):\n",
        "  done = False\n",
        "  score = 0\n",
        "  observation, info = env.reset()\n",
        "  while not done:\n",
        "    action = agent.choose_action(observation[0,:],observation)\n",
        "    observation_, reward, done, truncated, info = env.step(action)\n",
        "    score += reward\n",
        "    agent.store_transition(observation, action, reward, observation_, done)\n",
        "    agent.train()\n",
        "    # torch.save(agent.Q_fn.state_dict(),\"./intersection_weights\" )\n",
        "    observation = observation_\n",
        "  scores.append(score)\n",
        "  eps_history.append(agent.epsilon)\n",
        "\n",
        "  avg_score = np.mean(scores[-100:])\n",
        "  print('episode ', i, 'score %.2f' % score, 'average score %.2f' % avg_score,'epsilon %.2f' % agent.epsilon)\n"
      ],
      "metadata": {
        "id": "4lh8I47UbrSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize"
      ],
      "metadata": {
        "id": "HcPr9nT-nXIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# won't run have to edit\n",
        "\n",
        "env = gym.make(\"intersection-v0\",render_mode=\"rgb_array\")\n",
        "# Default Config: Observation: Kinematics, Actions: DiscreteMetaAction\n",
        "# ACTIONS_ALL = {0: 'LANE_LEFT',1: 'IDLE',2: 'LANE_RIGHT',3: 'FASTER',4: 'SLOWER'}\n",
        "# Obeservations : Vehicle x y vx vy / first row is always ego vehicle\n",
        "env = RecordVideo(env, video_folder=\"./videos\", episode_trigger=lambda e: True)\n",
        "observation, info = env.reset()\n",
        "done = False\n",
        "score = 0\n",
        "while not done:\n",
        "  ego = torch.tensor(ego_features).to(self.Q_fn.device).unsqueeze(0)\n",
        "  vehicles = torch.tensor(vehicle_features).to(self.Q_fn.device).unsqueeze(0)\n",
        "  q_values, _ = self.Q_fn(ego, vehicles)\n",
        "  action = torch.argmax(q_values).item()\n",
        "  state = torch.tensor(np.array(observation.reshape((1,-1)))).to(agent.Q_fn.device) ## may need to edit this\n",
        "  actions = agent.Q_fn.forward(state)\n",
        "  action = torch.argmax(actions).item()\n",
        "  obs, reward, done, truncated, info = env.step(action)\n",
        "  score += reward\n",
        "  observation = obs\n",
        "print('score %.2f' % score)\n",
        "env.close()\n",
        "show_videos()"
      ],
      "metadata": {
        "id": "WGjFtYH9eHbS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}