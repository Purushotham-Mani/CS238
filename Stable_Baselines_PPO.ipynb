{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install highway_env","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:02:09.499490Z","iopub.execute_input":"2024-12-09T03:02:09.500359Z","iopub.status.idle":"2024-12-09T03:02:21.818736Z","shell.execute_reply.started":"2024-12-09T03:02:09.500323Z","shell.execute_reply":"2024-12-09T03:02:21.817704Z"}},"outputs":[{"name":"stdout","text":"Collecting highway_env\n  Downloading highway_env-1.10.1-py3-none-any.whl.metadata (16 kB)\nCollecting gymnasium>=1.0.0a2 (from highway_env)\n  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from highway_env) (0.0.4)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from highway_env) (1.26.4)\nCollecting pygame>=2.0.2 (from highway_env)\n  Downloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from highway_env) (3.7.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from highway_env) (2.2.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from highway_env) (1.14.1)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=1.0.0a2->highway_env) (3.1.0)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=1.0.0a2->highway_env) (4.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->highway_env) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->highway_env) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->highway_env) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->highway_env) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->highway_env) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->highway_env) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->highway_env) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->highway_env) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->highway_env) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->highway_env) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->highway_env) (1.16.0)\nDownloading highway_env-1.10.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pygame, gymnasium, highway_env\n  Attempting uninstall: gymnasium\n    Found existing installation: gymnasium 0.29.0\n    Uninstalling gymnasium-0.29.0:\n      Successfully uninstalled gymnasium-0.29.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.9 requires gymnasium==0.29.0, but you have gymnasium 1.0.0 which is incompatible.\nstable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gymnasium-1.0.0 highway_env-1.10.1 pygame-2.6.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import gymnasium\nimport highway_env\nfrom stable_baselines3 import DQN,PPO\nfrom stable_baselines3.common.monitor import Monitor\nfrom stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\nimport wandb\nfrom stable_baselines3.common.callbacks import BaseCallback\nfrom stable_baselines3.common.utils import get_device\n\nimport numpy as np\nimport time\nimport warnings\nimport json\n\n# Suppress specific warnings\nwarnings.filterwarnings(\"ignore\") ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T04:52:52.176331Z","iopub.execute_input":"2024-12-09T04:52:52.176677Z","iopub.status.idle":"2024-12-09T04:52:52.181840Z","shell.execute_reply.started":"2024-12-09T04:52:52.176646Z","shell.execute_reply":"2024-12-09T04:52:52.180930Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"device = get_device()\nWANDB_LOG = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T04:52:55.656899Z","iopub.execute_input":"2024-12-09T04:52:55.657656Z","iopub.status.idle":"2024-12-09T04:52:55.661345Z","shell.execute_reply.started":"2024-12-09T04:52:55.657620Z","shell.execute_reply":"2024-12-09T04:52:55.660486Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"class CustomCallback(BaseCallback):\n    def __init__(self, verbose=0):\n        super(CustomCallback, self).__init__(verbose)\n        self.max_length_ep = 100\n        self.print_every = 10\n        self.ep_rewards = np.zeros(self.max_length_ep)\n        self.ep_speeds = np.zeros(self.max_length_ep)\n\n        self.total_step_counter = 0\n        self.step = 0\n        self.episode = 0\n        self.time_ep_start = time.time()\n        \n\n    def _on_step(self) -> bool:\n        # print(\"num_collected_steps: {} | total_timesteps: {} | num_collected_episodes: {} | rewards type : {}\".format(self.locals[\"num_collected_steps\"],\n        #                                                                                                          self.locals[\"total_timesteps\"],\n        #                                                                                                          self.locals[\"num_collected_episodes\"],\n        #                                                                                                          (self.locals[\"rewards\"]).shape))\n\n        done = self.locals[\"dones\"][0] # It is plural \"dones\" coz of multiple environment parallelisation\n        if done:\n\n            reward = self.locals[\"rewards\"][0]\n            speed = self.locals[\"infos\"][0][\"speed\"]\n            self.ep_rewards[self.step] = reward\n            self.ep_speeds[self.step] = speed\n    \n            self.time_ep_end = time.time()\n            duration = self.time_ep_end - self.time_ep_start\n            total_reward = self.ep_rewards.sum()\n            avg_speed = self.ep_speeds.mean()\n            crashed = self.locals[\"infos\"][0][\"crashed\"]\n\n\n            log_dict = {\"Episode\":self.episode,\n                        \"Episode Reward\":total_reward,\n                        \"Duration for Ep to Run\":duration,\n                        \"Episode Length\":self.step,\n                        \"Crashed\":int(crashed),\n                        \"Average Speed\":avg_speed\n            }\n            \n            if self.episode%self.print_every==0:\n            \n                print(\"Episode {} | Duration: {:.3f} | Total Step Counter: {}/{} | Episode Reward: {:.3f} | Avg Speed: {:.3f} | Crashed: {}\".format(self.episode,duration,\n                                                                                                                                                self.total_step_counter,\n                                                                                                                                                self.locals[\"total_timesteps\"],\n                                                                                                                                                total_reward,\n                                                                                                                                                avg_speed,crashed))\n            \n            # Do Wandb logging\n            if WANDB_LOG:\n                wandb.log(log_dict,step=self.episode)\n            \n            self.ep_rewards = np.zeros(self.max_length_ep)\n            self.ep_speeds = np.zeros(self.max_length_ep)\n            self.episode += 1\n            self.step = 0\n            self.time_ep_start = time.time()\n            \n        else:     \n            # print(\"Episode not ended\")\n            \n            reward = self.locals[\"rewards\"][0]\n            speed = self.locals[\"infos\"][0][\"speed\"]\n            self.ep_rewards[self.step] = reward\n            self.ep_speeds[self.step] = speed\n\n            self.step += 1\n\n        self.total_step_counter += 1\n        \n    \n        return True  # Continue training\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T04:52:58.073712Z","iopub.execute_input":"2024-12-09T04:52:58.074065Z","iopub.status.idle":"2024-12-09T04:52:58.084044Z","shell.execute_reply.started":"2024-12-09T04:52:58.074031Z","shell.execute_reply":"2024-12-09T04:52:58.083233Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"config_dict = {\"env_name\":\"highway-v0\",\n          \"project_name\":\"RoadSense\",\n          \"total_timesteps\":100,\n               \"absolute\":False,\n          \"model_save_path\":\"models/dqn_highway_100/model\",\n          \"env_config_save_path\":\"models/dqn_highway_vehicle/env_config.json\",\n          \"model_name\":\"model_name_ts_100\",\n          \"wandb_log\":WANDB_LOG,\n          \"verbose\":0}\n\nenv_config_dict = {'observation': {'type': 'Kinematics',\n  'vehicles_count': 6,\n  'features': ['presence', 'x', 'y', 'vx', 'vy'],\n  'features_range': {'x': [-100, 100],\n   'y': [-100, 100],\n   'vx': [-20, 20],\n   'vy': [-20, 20]},\n  'absolute': config_dict[\"absolute\"],\n  'flatten': False,\n  'observe_intentions': False},\n 'action': {'type': 'DiscreteMetaAction',\n  'longitudinal': True,\n  'lateral': False,\n  'target_speeds': [0, 4.5, 9]},\n 'simulation_frequency': 15,\n 'policy_frequency': 1,\n 'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle',\n 'screen_width': 600,\n 'screen_height': 600,\n 'centering_position': [0.5, 0.6],\n 'scaling': 7.15,\n 'show_trajectories': False,\n 'render_agent': True,\n 'offscreen_rendering': False,\n 'manual_control': False,\n 'real_time_rendering': False,\n 'duration': 13,\n 'destination': 'o1',\n 'controlled_vehicles': 1,\n 'initial_vehicle_count': 10,\n 'spawn_probability': 0.6,\n 'collision_reward': -10,\n 'high_speed_reward': 1,\n 'arrived_reward': 1.5,\n 'reward_speed_range': [7.0, 9.0],\n 'normalize_reward': False,\n 'offroad_terminal': False}\n\nenv = gymnasium.make(config_dict[\"env_name\"])#,config=env_config_dict)\nenv = Monitor(env)\n\nwandb_log = config_dict[\"wandb_log\"]\n\nif wandb_log:\n    run = wandb.init(\n        project=\"RoadSense\",\n        config = config_dict\n    )\nmodel = DQN('MlpPolicy', env,\n              policy_kwargs=dict(net_arch=[256, 256]),\n              learning_rate=5e-4,\n              buffer_size=15000,\n              learning_starts=200,\n              batch_size=32,\n              gamma=0.8,\n              train_freq=1,\n              gradient_steps=1,\n              target_update_interval=50,\n              verbose=1,\n              tensorboard_log=\"highway_dqn/\")\n            \n# model = DQN('MlpPolicy', env,\n#               policy_kwargs=dict(net_arch=[256, 256]),\n#               learning_rate=5e-4,\n#               buffer_size=15000,\n#               learning_starts=20,\n#               batch_size=32,\n#               gamma=0.8,\n#               train_freq=1,\n#               gradient_steps=1,\n#               target_update_interval=50,\n#               verbose=0,\n#                device = device)\n\n# tensorboard_log=\"logs/{}\".format(config_dict[\"model_name\"])\n\nmodel.learn(total_timesteps=config_dict[\"total_timesteps\"],callback=CustomCallback(config_dict[\"verbose\"]))\nmodel.save(config_dict[\"model_save_path\"])\n\n# with open(config_dict[\"env_config_save_path\"], 'w') as f:\n#     json.dump(env_config_dict, f)\n\nif wandb_log:\n    run.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T08:57:07.461155Z","iopub.execute_input":"2024-12-09T08:57:07.461558Z","iopub.status.idle":"2024-12-09T08:57:50.323292Z","shell.execute_reply.started":"2024-12-09T08:57:07.461523Z","shell.execute_reply":"2024-12-09T08:57:50.322534Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:pcuw4492) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Speed</td><td>▂▁▆▄▄▅▃▄▅▅▅▃▃▂▂▁▃▁▆▄▅▆▄▃▅▁▆▃▂█▄▃▃▆▄▃▄▅▄▂</td></tr><tr><td>Crashed</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Duration for Ep to Run</td><td>█▄▁▁▁▂▁▆▃▅▅▄▃▂▄▂▄▃▃▃▂▃▂▃▄▄▄▂▃▄▄▁▅▅▄▃▃▅▃▃</td></tr><tr><td>Episode</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>Episode Length</td><td>█▅▅▂▂▁▃▇▁▁▃▂▂▃▃▂▄▄▆▄▂▂▄▅▃▁▂▅▃▁▃▄█▄▄▂▂▄▅▃</td></tr><tr><td>Episode Reward</td><td>▁▄▁▂▁▂▂▃█▄▄▂▃█▃▂▄▁▁▂▄▄▃▅▃▁▁▇▄▅▃▃▂▆▅▄▅▆▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Speed</td><td>2.64848</td></tr><tr><td>Crashed</td><td>1</td></tr><tr><td>Duration for Ep to Run</td><td>3.77861</td></tr><tr><td>Episode</td><td>166</td></tr><tr><td>Episode Length</td><td>9</td></tr><tr><td>Episode Reward</td><td>8.45693</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">genial-sun-39</strong> at: <a href='https://wandb.ai/crna/RoadSense/runs/pcuw4492' target=\"_blank\">https://wandb.ai/crna/RoadSense/runs/pcuw4492</a><br/> View project at: <a href='https://wandb.ai/crna/RoadSense' target=\"_blank\">https://wandb.ai/crna/RoadSense</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241209_084121-pcuw4492/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:pcuw4492). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241209_085707-sgcca1zu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/crna/RoadSense/runs/sgcca1zu' target=\"_blank\">twilight-pond-40</a></strong> to <a href='https://wandb.ai/crna/RoadSense' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/crna/RoadSense' target=\"_blank\">https://wandb.ai/crna/RoadSense</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/crna/RoadSense/runs/sgcca1zu' target=\"_blank\">https://wandb.ai/crna/RoadSense/runs/sgcca1zu</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n","output_type":"stream"},{"name":"stdout","text":"Using cuda device\nWrapping the env in a DummyVecEnv.\nLogging to highway_dqn/DQN_1\nEpisode 0 | Duration: 3.124 | Total Step Counter: 7/100 | Episode Reward: 5.597 | Avg Speed: 1.753 | Crashed: True\n----------------------------------\n| rollout/            |          |\n|    ep_len_mean      | 8.5      |\n|    ep_rew_mean      | 5.98     |\n|    exploration_rate | 0.05     |\n| time/               |          |\n|    episodes         | 4        |\n|    fps              | 2        |\n|    time_elapsed     | 13       |\n|    total_timesteps  | 34       |\n----------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Speed</td><td>▂▁▄▁▁█</td></tr><tr><td>Crashed</td><td>▁▁▁▁▁▁</td></tr><tr><td>Duration for Ep to Run</td><td>▂▁▄▁▁█</td></tr><tr><td>Episode</td><td>▁▂▄▅▇█</td></tr><tr><td>Episode Length</td><td>▂▁▄▁▁█</td></tr><tr><td>Episode Reward</td><td>▂▁▄▁▁█</td></tr><tr><td>global_step</td><td>▁▁▁▁</td></tr><tr><td>rollout/ep_len_mean</td><td>▁</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁</td></tr><tr><td>rollout/exploration_rate</td><td>▁</td></tr><tr><td>time/fps</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Speed</td><td>6.31821</td></tr><tr><td>Crashed</td><td>1</td></tr><tr><td>Duration for Ep to Run</td><td>10.73727</td></tr><tr><td>Episode</td><td>5</td></tr><tr><td>Episode Length</td><td>26</td></tr><tr><td>Episode Reward</td><td>20.5061</td></tr><tr><td>global_step</td><td>34</td></tr><tr><td>rollout/ep_len_mean</td><td>8.5</td></tr><tr><td>rollout/ep_rew_mean</td><td>5.97517</td></tr><tr><td>rollout/exploration_rate</td><td>0.05</td></tr><tr><td>time/fps</td><td>2</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">twilight-pond-40</strong> at: <a href='https://wandb.ai/crna/RoadSense/runs/sgcca1zu' target=\"_blank\">https://wandb.ai/crna/RoadSense/runs/sgcca1zu</a><br/> View project at: <a href='https://wandb.ai/crna/RoadSense' target=\"_blank\">https://wandb.ai/crna/RoadSense</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241209_085707-sgcca1zu/logs</code>"},"metadata":{}}],"execution_count":95},{"cell_type":"code","source":"# Load and test saved model\nenv = gymnasium.make(config_dict[\"env_name\"])\nmodel = DQN.load(config_dict[\"model_save_path\"])\nwhile True:\n    done = truncated = False\n    obs, info = env.reset()\n    while not (done or truncated):\n        action, _states = model.predict(obs, deterministic=True)\n        obs, reward, done, truncated, info = env.step(action)\n        print(\"Reward : {:.3f} | Action: {}\".format(reward,action))\n\n    break    \n    # env.render()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}